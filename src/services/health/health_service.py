import os
import csv
try:
    # lxml ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚Œã°é«˜é€Ÿã«ãƒ‘ãƒ¼ã‚¹ã§ãã‚‹
    from lxml import etree as ET
except ImportError:
    import xml.etree.ElementTree as ET
from datetime import datetime, timezone, timedelta
from tqdm import tqdm

from services.health.record_types import SERVICE_MAPPING

JST = timezone(timedelta(hours=9))


class FileWithProgress:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒ©ãƒƒãƒ—ã—ã€readæ™‚ã«tqdmã®é€²æ—ãƒãƒ¼ã‚’æ›´æ–°ã™ã‚‹ã‚¯ãƒ©ã‚¹
    """

    def __init__(self, file_obj, pbar):
        self.file_obj = file_obj
        self.pbar = pbar

    def read(self, size):
        data = self.file_obj.read(size)
        self.pbar.update(len(data))
        return data

    def readline(self, *args, **kwargs):
        line = self.file_obj.readline(*args, **kwargs)
        self.pbar.update(len(line))
        return line

    def __iter__(self):
        return iter(self.file_obj)

    def __getattr__(self, attr):
        return getattr(self.file_obj, attr)


class HealthService:
    """Apple Health ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆé«˜é€ŸåŒ–å¯¾å¿œç‰ˆï¼‰"""

    def __init__(self):
        pass

    def parse_and_save(self, xml_file):
        """
        XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’1å›ã®ãƒ‘ãƒ¼ã‚¹ã§å‡¦ç†ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã«åŸºã¥ããƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã§é€²æ—ã‚’è¡¨ç¤ºã—ãªãŒã‚‰
        CSVã«ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ä¿å­˜ã™ã‚‹
        """
        total_size = os.path.getsize(xml_file)
        print(f"ğŸ” å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {total_size / (1024*1024):.2f} MB")

        # record_typeï¼ˆã‚µãƒ¼ãƒ“ã‚¹ï¼‰æ¯ã«ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼ˆè¾æ›¸ï¼‰ã‚’ã¾ã¨ã‚ã‚‹è¾æ›¸ã‚’ç”¨æ„
        grouped_records = {}

        with open(xml_file, 'rb') as f:
            with tqdm(total=total_size, desc="Processing Records", unit="B", unit_scale=True) as pbar:
                file_with_progress = FileWithProgress(f, pbar)
                # iterparse ã§XMLã‚’é€æ¬¡å‡¦ç†
                context = ET.iterparse(file_with_progress, events=("start",))
                for _, elem in context:
                    if elem.tag == "Record":
                        record_type = elem.get("type")
                        id_ = None
                        source_name = elem.get("sourceName")
                        creation_date_str = elem.get("creationDate")
                        start_date_str = elem.get("startDate")
                        end_date_str = elem.get("endDate")
                        unit = elem.get("unit")
                        duration = None
                        value = elem.get("value")

                        # æ—¥æ™‚æ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã€æ—¥æœ¬æ™‚é–“ã«å¤‰æ›
                        creation_date = datetime.strptime(creation_date_str, "%Y-%m-%d %H:%M:%S %z").astimezone(JST)
                        start_date = datetime.strptime(start_date_str, "%Y-%m-%d %H:%M:%S %z").astimezone(JST)
                        end_date = datetime.strptime(end_date_str, "%Y-%m-%d %H:%M:%S %z").astimezone(JST)
                        duration = (end_date - start_date).total_seconds()

                        data = {
                            "id": id_,
                            "source_name": source_name,
                            "creation_date": creation_date,
                            "start_date": start_date,
                            "end_date": end_date,
                            "unit": unit,
                            "duration": duration,
                            "value": value
                        }

                        grouped_records.setdefault(record_type, []).append(data)
                        elem.clear()

        for record_type, records in grouped_records.items():
            service_cls = SERVICE_MAPPING.get(record_type)
            if service_cls is None:
                print(f"âš ï¸ å¯¾å¿œã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {record_type}")
                continue
            service_instance = service_cls()
            # ã“ã“ã§ process() ã‚’ã€è¤‡æ•°ä»¶å‡¦ç†ã§ãã‚‹ã‚ˆã†ã«ï¼ˆä¾‹ï¼šãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚‹ã‚ˆã†ã«ï¼‰å®Ÿè£…
            service_instance.process(records)
